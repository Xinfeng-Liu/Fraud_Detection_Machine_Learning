{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9592a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a79122a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import files\n",
    "\n",
    "#Training data\n",
    "training_file = 'b765dc3d8076-trainset+(1).xlsx'\n",
    "if exists(training_file):\n",
    "    training_data = pd.read_excel('b765dc3d8076-trainset+(1).xlsx') \n",
    "else:\n",
    "    training_data = pd.read_excel('https://d18qs7yq39787j.cloudfront.net/uploads/contestfile/479/b765dc3d8076-trainset+%281%29.xlsx')\n",
    "\n",
    "# Testing data\n",
    "testing_file = 'b765dc3d8076-testset_for_participants.xlsx'   \n",
    "if exists(testing_file):\n",
    "    testing_data = pd.read_excel('b765dc3d8076-testset_for_participants.xlsx')\n",
    "else:\n",
    "    testing_data = pd.read_excel('https://d18qs7yq39787j.cloudfront.net/uploads/contestfile/479/b765dc3d8076-testset_for_participants.xlsx')\n",
    "data = [training_data, testing_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd0ab8d",
   "metadata": {},
   "source": [
    "# I. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8ded4",
   "metadata": {},
   "source": [
    "## 1. Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7ca5108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Stats507/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/opt/anaconda3/envs/Stats507/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/opt/anaconda3/envs/Stats507/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "for df in data:\n",
    "    # CARR_NAME，RGN_NAME，STATE_PRVNC_TXT\n",
    "    for i in ['CARR_NAME','RGN_NAME','STATE_PRVNC_TXT']:\n",
    "        df[i].fillna('unknown', inplace = True)\n",
    "    \n",
    "    # DVC_TYPE_TXT & AUTHC_SCNDRY_STAT_TXT\n",
    "    authc_data = df[['ALERT_TRGR_CD','DVC_TYPE_TXT','AUTHC_PRIM_TYPE_CD','AUTHC_SCNDRY_STAT_TXT']]\n",
    "    cat_feature = list(authc_data.columns)\n",
    "    enc_authc_data = authc_data.copy()\n",
    "    for i in cat_feature:\n",
    "        enc = LabelEncoder()\n",
    "        enc.fit(list(enc_authc_data[i].values));\n",
    "        enc_authc_data[i] = enc.transform(list(enc_authc_data[i].values))\n",
    "    enc_authc_data['DVC_TYPE_TXT'].loc[enc_authc_data['DVC_TYPE_TXT'] == 4] = np.nan\n",
    "    enc_authc_data['AUTHC_SCNDRY_STAT_TXT'].loc[enc_authc_data['AUTHC_SCNDRY_STAT_TXT'] == 3] = np.nan\n",
    "    #imput enc_authc_data\n",
    "    imputer = KNNImputer(n_neighbors=2)\n",
    "    imputed = pd.DataFrame(imputer.fit_transform(enc_authc_data))\n",
    "    imputed = imputed.rename(columns = {0:'ALERT_TRGR_CD',\n",
    "                                        1:'DVC_TYPE_TXT',\n",
    "                                        2:'AUTHC_PRIM_TYPE_CD',\n",
    "                                        3:'AUTHC_SCNDRY_STAT_TXT'})\n",
    "    #after imputation, DVC_TYPE_TXT has new value 0.5&1.5, whic isn't in original data, repalce 0.5&1.5with 1&2 \n",
    "    imputed['DVC_TYPE_TXT'].loc[imputed['DVC_TYPE_TXT'] == 0.5] = 1\n",
    "    imputed['DVC_TYPE_TXT'].loc[imputed['DVC_TYPE_TXT'] == 1.5] = 2\n",
    "\n",
    "    imputed = imputed.astype(int)\n",
    "    #mapping back to real info\n",
    "    imputed['DVC_TYPE_TXT'].loc[imputed['DVC_TYPE_TXT'] == 0] = 'DESKTOP'\n",
    "    imputed['DVC_TYPE_TXT'].loc[imputed['DVC_TYPE_TXT'] == 1] = 'MOBILE'\n",
    "    imputed['DVC_TYPE_TXT'].loc[imputed['DVC_TYPE_TXT'] == 2] = 'PHONE'\n",
    "    imputed['DVC_TYPE_TXT'].loc[imputed['DVC_TYPE_TXT'] == 3] = 'TABLET'\n",
    "    imputed['AUTHC_SCNDRY_STAT_TXT'].loc[imputed['AUTHC_SCNDRY_STAT_TXT'] == 0] = 'ALLOW'\n",
    "    imputed['AUTHC_SCNDRY_STAT_TXT'].loc[imputed['AUTHC_SCNDRY_STAT_TXT'] == 1] = 'CHALLENGE_ISSUED'\n",
    "    imputed['AUTHC_SCNDRY_STAT_TXT'].loc[imputed['AUTHC_SCNDRY_STAT_TXT'] == 2] = 'CHALLENGE_SUCCESS'\n",
    "    df['DVC_TYPE_TXT'] = imputed['DVC_TYPE_TXT']\n",
    "    df['AUTHC_SCNDRY_STAT_TXT'] = imputed['AUTHC_SCNDRY_STAT_TXT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cedefd7",
   "metadata": {},
   "source": [
    "## 2. Handle Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "603399a6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_DT'][i] = df['TRAN_DT'][i].strftime('%m/%d/%Y')\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ACTVY_DT'][i] = df['ACTVY_DT'][i].strftime('%m/%d/%Y')\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_DT_month'][i] = df['TRAN_DT'][i].split('/')[0]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_DT_day'][i] = df['TRAN_DT'][i].split('/')[1]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_DT_year'][i] = df['TRAN_DT'][i].split('/')[2]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ACTVY_DT_month'][i] = df['ACTVY_DT'][i].split('/')[0]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ACTVY_DT_day'][i] = df['ACTVY_DT'][i].split('/')[1]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ACTVY_DT_year'][i] = df['ACTVY_DT'][i].split('/')[2]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_TS'][i] = df['TRAN_TS'][i].strftime('%m/%d/%Y %H:%M:%S')\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_TS_date'][i] = df['TRAN_TS'][i].split(' ')[0]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_TS_time'][i] = df['TRAN_TS'][i].split(' ')[1]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_TS_date_month'][i] = df['TRAN_TS_date'][i].split('/')[0]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_TS_date_day'][i] = df['TRAN_TS_date'][i].split('/')[1]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_TS_date_year'][i] = df['TRAN_TS_date'][i].split('/')[2]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_TS_time_hr'][i] = df['TRAN_TS_time'][i].split(':')[0]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_TS_time_min'][i] = df['TRAN_TS_time'][i].split(':')[1]\n",
      "/var/folders/8_/j14vrxnx2cz8yhy96kx5x_3h0000gn/T/ipykernel_62137/3770968757.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TRAN_TS_time_sec'][i] = df['TRAN_TS_time'][i].split(':')[2]\n"
     ]
    }
   ],
   "source": [
    "for df in data:\n",
    "    # change CUST_SINCE_DT to string\n",
    "    df['CUST_SINCE_DT'] = df['CUST_SINCE_DT'].astype(str)\n",
    "    # split year, month, day for TRAN_DT, ACTVY_DT\n",
    "    for i in ['TRAN_DT', 'ACTVY_DT']:\n",
    "        df[[i+'_month',i+'_day', i+'_year']] = df[i].str.split('/', expand = True)\n",
    "    # there are some TRAN_DT & ACTVY_DT with different format:2021-8-2 12:00:00 AM, transfer to correct format\n",
    "    wrong_format_list = df[df['ACTVY_DT_month'].isnull()].index.tolist()\n",
    "    for i in wrong_format_list:\n",
    "        df['TRAN_DT'][i] = df['TRAN_DT'][i].strftime('%m/%d/%Y')\n",
    "        df['ACTVY_DT'][i] = df['ACTVY_DT'][i].strftime('%m/%d/%Y')\n",
    "        df['TRAN_DT_month'][i] = df['TRAN_DT'][i].split('/')[0]\n",
    "        df['TRAN_DT_day'][i] = df['TRAN_DT'][i].split('/')[1]\n",
    "        df['TRAN_DT_year'][i] = df['TRAN_DT'][i].split('/')[2]\n",
    "        df['ACTVY_DT_month'][i] = df['ACTVY_DT'][i].split('/')[0]\n",
    "        df['ACTVY_DT_day'][i] = df['ACTVY_DT'][i].split('/')[1]\n",
    "        df['ACTVY_DT_year'][i] = df['ACTVY_DT'][i].split('/')[2]\n",
    "    # split year, month, day for CUST_SINCE_DT\n",
    "    df[['CUST_SINCE_DT'+'_year', \n",
    "        'CUST_SINCE_DT'+'_month', \n",
    "        'CUST_SINCE_DT'+'_day']] = df['CUST_SINCE_DT'].str.split('-', expand = True)\n",
    "\n",
    "    # split date and time of PWD_UPDT_TS, TRAN_TS\n",
    "    for i in ['PWD_UPDT_TS', 'TRAN_TS']:\n",
    "        df[[i+'_date', i+'_time']] = df[i].str.split(' ', expand = True)\n",
    "    # split year, month date for PWD_UPDT_TS, TRAN_TS\n",
    "    for i in ['PWD_UPDT_TS_date', 'TRAN_TS_date']:\n",
    "        df[[i+'_month', i+'_day', i+'_year']] = df[i].str.split('/', expand = True)\n",
    "    # split hour, minute, and second for PWD_UPDT_TS, TRAN_TS\n",
    "    for i in ['PWD_UPDT_TS_time', 'TRAN_TS_time']:\n",
    "        df[[i+'_hr', i+'_min', i+'_sec']] = df[i].str.split(':', expand = True)\n",
    "    # there are some TRAN_TS with different format:2021-8-2 12:00:00 AM, transfer to correct format\n",
    "    wrong_format_list2 = df[df['TRAN_TS_date_month'].isnull()].index.tolist()\n",
    "    for i in wrong_format_list2:\n",
    "        df['TRAN_TS'][i] = df['TRAN_TS'][i].strftime('%m/%d/%Y %H:%M:%S')\n",
    "        df['TRAN_TS_date'][i] = df['TRAN_TS'][i].split(' ')[0]\n",
    "        df['TRAN_TS_time'][i] = df['TRAN_TS'][i].split(' ')[1]\n",
    "        df['TRAN_TS_date_month'][i] = df['TRAN_TS_date'][i].split('/')[0]\n",
    "        df['TRAN_TS_date_day'][i] = df['TRAN_TS_date'][i].split('/')[1]\n",
    "        df['TRAN_TS_date_year'][i] = df['TRAN_TS_date'][i].split('/')[2]\n",
    "        df['TRAN_TS_time_hr'][i] = df['TRAN_TS_time'][i].split(':')[0]\n",
    "        df['TRAN_TS_time_min'][i] = df['TRAN_TS_time'][i].split(':')[1]\n",
    "        df['TRAN_TS_time_sec'][i] = df['TRAN_TS_time'][i].split(':')[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d024fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some colums for easier understanding\n",
    "rename_dic = {'PWD_UPDT_TS_date_year':'PWD_UPDT_TS_year',\n",
    "              'PWD_UPDT_TS_date_month':'PWD_UPDT_TS_month',\n",
    "              'PWD_UPDT_TS_date_day':'PWD_UPDT_TS_day',\n",
    "              'TRAN_TS_date_year':'TRAN_TS_year',\n",
    "              'TRAN_TS_date_month':'TRAN_TS_month',\n",
    "              'TRAN_TS_date_day':'TRAN_TS_day',\n",
    "              'PWD_UPDT_TS_time_hr':'PWD_UPDT_TS_hr',\n",
    "              'PWD_UPDT_TS_time_min':'PWD_UPDT_TS_min',\n",
    "              'PWD_UPDT_TS_time_sec':'PWD_UPDT_TS_sec',\n",
    "              'TRAN_TS_time_hr':'TRAN_TS_hr',\n",
    "              'TRAN_TS_time_min':'TRAN_TS_min',\n",
    "              'TRAN_TS_time_sec':'TRAN_TS_sec'}\n",
    "    \n",
    "testing_data = testing_data.rename(columns = rename_dic)\n",
    "training_data = training_data.rename(columns = rename_dic)\n",
    "\n",
    "#deleted PWD_UPDT_TS_date & TRAN_TS_date first slipt columns\n",
    "del testing_data['PWD_UPDT_TS_date']\n",
    "del testing_data['PWD_UPDT_TS_time']\n",
    "del testing_data['TRAN_TS_date']\n",
    "del testing_data['TRAN_TS_time']\n",
    "\n",
    "del training_data['PWD_UPDT_TS_date']\n",
    "del training_data['PWD_UPDT_TS_time']\n",
    "del training_data['TRAN_TS_date']\n",
    "del training_data['TRAN_TS_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dbe9f9",
   "metadata": {},
   "source": [
    "## 3. Drop Useless Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1bdc2f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delete_col = ['ACTVY_DT_year', \n",
    "              'ACTVY_DT_month',\n",
    "              'ACTVY_DT_day',\n",
    "              'TRAN_TS_year',\n",
    "              'CUST_STATE',\n",
    "              'PH_NUM_UPDT_TS',\n",
    "              'PWD_UPDT_TS',\n",
    "              'PWD_UPDT_TS_month',\n",
    "              'PWD_UPDT_TS_day',\n",
    "              'PWD_UPDT_TS_year',\n",
    "              'PWD_UPDT_TS_hr',\n",
    "              'PWD_UPDT_TS_min',\n",
    "              'PWD_UPDT_TS_sec',\n",
    "              'TRAN_DT',\n",
    "              'TRAN_DT_year', \n",
    "              'TRAN_DT_month',\n",
    "              'TRAN_DT_day',\n",
    "              'CUST_SINCE_DT',\n",
    "              'TRAN_TS',\n",
    "              'ACTVY_DT',\n",
    "              'CUST_ZIP',\n",
    "              'ACTN_CD',\n",
    "              'ACTN_INTNL_TXT',\n",
    "              'TRAN_TYPE_CD']\n",
    "for col in delete_col:\n",
    "    del training_data[col]\n",
    "    del testing_data[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85256463",
   "metadata": {},
   "source": [
    "## 3. Change year, month, day, hour, minute, second to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "30e8679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "astype_col = ['CUST_SINCE_DT_year', 'CUST_SINCE_DT_month', 'CUST_SINCE_DT_day',\n",
    "              'TRAN_TS_month', 'TRAN_TS_day', \n",
    "              'TRAN_TS_hr', 'TRAN_TS_min', 'TRAN_TS_sec']\n",
    "\n",
    "testing_data[astype_col] = testing_data[astype_col].astype('int64')\n",
    "training_data[astype_col] = training_data[astype_col].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb91fb",
   "metadata": {},
   "source": [
    "## 4. Set dataset_id as index for testing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "bfea9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = testing_data.set_index('dataset_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc8506",
   "metadata": {},
   "source": [
    "## 5. Change target value to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "80f97852",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# change target value to binary\n",
    "training_data['FRAUD_NONFRAUD'] = np.where(training_data['FRAUD_NONFRAUD']=='Non-Fraud', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b7c4a",
   "metadata": {},
   "source": [
    "## 6. Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab9baa",
   "metadata": {},
   "source": [
    "1. CARR_NAME has 554 distinct categories, and STATE_PRVNC_TXT has 127 distinct categories. If one-hot encoding, will created a highly sparsed dataset. Therefore, we will binary encoding these two featurs.\n",
    "\n",
    "2. For the rest of categorical features:RGN_NAME, ALERT_TRGR_CD, DVC_TYPE_TXT, AUTHC_PRIM_TYPE_CD, and AUTHC_SCNDRY_STAT_TXT, we will use one hot encoding technique. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37773ca3",
   "metadata": {},
   "source": [
    "### (1). Binary Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ea432fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Stats507/lib/python3.9/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "binary_enc = ce.BinaryEncoder(cols=['CARR_NAME', 'STATE_PRVNC_TXT'],return_df=True)\n",
    "features = training_data.drop(['FRAUD_NONFRAUD'], axis=1)\n",
    "encoded_train_data = binary_enc.fit_transform(features)\n",
    "encoded_test_data = binary_enc.transform(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a2069",
   "metadata": {},
   "source": [
    "### (2). One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3a2cf13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_enc = ce.OneHotEncoder(cols=['RGN_NAME', \n",
    "                                 'ALERT_TRGR_CD', \n",
    "                                 'DVC_TYPE_TXT', \n",
    "                                 'AUTHC_PRIM_TYPE_CD', \n",
    "                                 'AUTHC_SCNDRY_STAT_TXT'], \n",
    "                           return_df=True)\n",
    "\n",
    "encoded_train_data = ohe_enc.fit_transform(encoded_train_data)\n",
    "encoded_test_data = ohe_enc.transform(encoded_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff45ed",
   "metadata": {},
   "source": [
    "# II. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392e149",
   "metadata": {},
   "source": [
    "## 1. Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e9fa3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoded_train_data\n",
    "y = training_data['FRAUD_NONFRAUD'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2d12ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split traning and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "50e09937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8562d3",
   "metadata": {},
   "source": [
    "### (1). Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3bb334d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.408\n",
      "R-squared score (test): 0.438\n"
     ]
    }
   ],
   "source": [
    "linridge = Ridge(alpha=1).fit(X_train_scaled, y_train)\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e59c4",
   "metadata": {},
   "source": [
    "### (2). Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "48f4f158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.000\n",
      "R-squared score (test): -0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linlasso = Lasso(alpha=1.0).fit(X_train_scaled, y_train)\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linlasso.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1534d00",
   "metadata": {},
   "source": [
    "### (3). Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c53c0b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.74\n",
      "Accuracy of Logistic regression classifier on test set: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.63      0.30      0.40      1054\n",
      "    NonFraud       0.75      0.93      0.83      2446\n",
      "\n",
      "    accuracy                           0.74      3500\n",
      "   macro avg       0.69      0.61      0.62      3500\n",
      "weighted avg       0.72      0.74      0.70      3500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Stats507/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "clf_predict = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "print(classification_report(y_test, clf_predict, target_names=['Fraud', 'NonFraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6f81c1",
   "metadata": {},
   "source": [
    "### (4). Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6ee667ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Dummy classifier on training set: 0.58\n",
      "Accuracy of Dummy classifier on test set: 0.60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.32      0.32      0.32      1054\n",
      "    NonFraud       0.71      0.71      0.71      2446\n",
      "\n",
      "    accuracy                           0.59      3500\n",
      "   macro avg       0.52      0.52      0.52      3500\n",
      "weighted avg       0.59      0.59      0.59      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_dummy = DummyClassifier(strategy='stratified').fit(X_train, y_train)\n",
    "clf_dummy_pred = clf_dummy.predict(X_test)\n",
    "\n",
    "print('Accuracy of Dummy classifier on training set: {:.2f}'\n",
    "     .format(clf_dummy.score(X_train, y_train)))\n",
    "print('Accuracy of Dummy classifier on test set: {:.2f}'\n",
    "     .format(clf_dummy.score(X_test, y_test)))\n",
    "\n",
    "print(classification_report(y_test, clf_dummy_pred, target_names=['Fraud', 'NonFraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69101d",
   "metadata": {},
   "source": [
    "### (5). KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "1b8fe0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.90\n",
      "Accuracy of KNN classifier on test set: 0.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.80      0.77      0.78      1054\n",
      "    NonFraud       0.90      0.92      0.91      2446\n",
      "\n",
      "    accuracy                           0.87      3500\n",
      "   macro avg       0.85      0.84      0.85      3500\n",
      "weighted avg       0.87      0.87      0.87      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "clf_knn_pred = clf_knn.predict(X_test)\n",
    "\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(clf_knn.score(X_train, y_train)))\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(clf_knn.score(X_test, y_test)))\n",
    "\n",
    "print(classification_report(y_test, clf_knn_pred, target_names=['Fraud', 'NonFraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8eb122",
   "metadata": {},
   "source": [
    "### (6). SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "5f99e795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.91\n",
      "Accuracy of SVM classifier on test set: 0.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.84      0.72      0.78      1054\n",
      "    NonFraud       0.89      0.94      0.91      2446\n",
      "\n",
      "    accuracy                           0.87      3500\n",
      "   macro avg       0.86      0.83      0.84      3500\n",
      "weighted avg       0.87      0.87      0.87      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVC().fit(X_train_scaled, y_train)\n",
    "clf_svm_pred = clf_svm.predict(X_test_scaled)\n",
    "\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(clf_svm.score(X_train_scaled, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(clf_svm.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(classification_report(y_test, clf_svm_pred, target_names=['Fraud', 'NonFraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7f0f2",
   "metadata": {},
   "source": [
    "### (7). Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c215690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.87      0.87      0.87      1054\n",
      "    NonFraud       0.95      0.95      0.95      2446\n",
      "\n",
      "    accuracy                           0.92      3500\n",
      "   macro avg       0.91      0.91      0.91      3500\n",
      "weighted avg       0.92      0.92      0.92      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_DT = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "clf_DT_pred = clf_DT.predict(X_test)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf_DT.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf_DT.score(X_test, y_test)))\n",
    "print(classification_report(y_test, clf_DT_pred, target_names=['Fraud', 'NonFraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345ff97",
   "metadata": {},
   "source": [
    "### (8). Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "78493e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest classifier on training set: 1.00\n",
      "Accuracy of Random Forest classifier on test set: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.94      0.88      0.91      1054\n",
      "    NonFraud       0.95      0.98      0.96      2446\n",
      "\n",
      "    accuracy                           0.95      3500\n",
      "   macro avg       0.95      0.93      0.94      3500\n",
      "weighted avg       0.95      0.95      0.95      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_RF = RandomForestClassifier().fit(X_train, y_train)\n",
    "clf_RF_pred = clf_RF.predict(X_test)\n",
    "\n",
    "print('Accuracy of Random Forest classifier on training set: {:.2f}'\n",
    "     .format(clf_RF.score(X_train, y_train)))\n",
    "print('Accuracy of Random Forest classifier on test set: {:.2f}'\n",
    "     .format(clf_RF.score(X_test, y_test)))\n",
    "print(classification_report(y_test, clf_RF_pred, target_names=['Fraud', 'NonFraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b456860",
   "metadata": {},
   "source": [
    "### (9). Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "053854a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gradient Boosting classifier on training set: 0.96\n",
      "Accuracy of Gradient Boosting classifier on test set: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.95      0.91      0.93      1054\n",
      "    NonFraud       0.96      0.98      0.97      2446\n",
      "\n",
      "    accuracy                           0.96      3500\n",
      "   macro avg       0.96      0.94      0.95      3500\n",
      "weighted avg       0.96      0.96      0.96      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_GB = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "clf_GB_pred = clf_GB.predict(X_test)\n",
    "\n",
    "print('Accuracy of Gradient Boosting classifier on training set: {:.2f}'\n",
    "     .format(clf_GB.score(X_train, y_train)))\n",
    "print('Accuracy of Gradient Boosting classifier on test set: {:.2f}'\n",
    "     .format(clf_GB.score(X_test, y_test)))\n",
    "print(classification_report(y_test, clf_GB_pred, target_names=['Fraud', 'NonFraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c740719f",
   "metadata": {},
   "source": [
    "### (10). AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "3624afe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoosting classifier on training set: 0.95\n",
      "Accuracy of AdaBoosting classifier on test set: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.96      0.94      0.95      1054\n",
      "    NonFraud       0.97      0.98      0.98      2446\n",
      "\n",
      "    accuracy                           0.97      3500\n",
      "   macro avg       0.97      0.96      0.96      3500\n",
      "weighted avg       0.97      0.97      0.97      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_ADB = AdaBoostClassifier().fit(X_train, y_train)\n",
    "clf_ADB_pred = clf_ADB.predict(X_test)\n",
    "\n",
    "print('Accuracy of AdaBoosting classifier on training set: {:.2f}'\n",
    "     .format(clf_ADB.score(X_train, y_train)))\n",
    "print('Accuracy of AdaBoosting classifier on test set: {:.2f}'\n",
    "     .format(clf_ADB.score(X_test, y_test)))\n",
    "print(classification_report(y_test, clf_XGB_pred, target_names=['Fraud', 'NonFraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a8f04",
   "metadata": {},
   "source": [
    "### (11). XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "8a0eb644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:09:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of XGBoosting classifier on training set: 0.98\n",
      "Accuracy of XGBoosting classifier on test set: 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.96      0.94      0.95      1054\n",
      "    NonFraud       0.97      0.98      0.98      2446\n",
      "\n",
      "    accuracy                           0.97      3500\n",
      "   macro avg       0.97      0.96      0.96      3500\n",
      "weighted avg       0.97      0.97      0.97      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_XGB = xgb.XGBClassifier(use_label_encoder=False, max_depth = 3).fit(X_train, y_train)\n",
    "clf_XGB_pred = clf_XGB.predict(X_test)\n",
    "\n",
    "print('Accuracy of XGBoosting classifier on training set: {:.2f}'\n",
    "     .format(clf_XGB.score(X_train, y_train)))\n",
    "print('Accuracy of XGBoosting classifier on test set: {:.2f}'\n",
    "     .format(clf_XGB.score(X_test, y_test)))\n",
    "print(classification_report(y_test, clf_XGB_pred, target_names=['Fraud', 'NonFraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f5dc1",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4f9b04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'learning_rate': [0.01, 0.02, 0.03, 0.04],\n",
    "              'max_depth': [3, 5, 7, 9],\n",
    "              'min_child_weight': [3, 5, 7, 9, 11, 20],\n",
    "              'subsample': [0.5, 0.7, 1.0],\n",
    "              'colsample_bytree': [0.5],\n",
    "              'n_estimators' : [100, 140, 165, 200, 220, 250]\n",
    "             }\n",
    "def param_tunning():\n",
    "    model = xgb.XGBClassifier()\n",
    "    clf = GridSearchCV(estimator=model, \n",
    "                       param_grid=parameters,\n",
    "                       cv=5,\n",
    "                       n_jobs=-1,\n",
    "                       verbose=1,\n",
    "                       use_label_encoder=False)\n",
    "    best_model = clf.fit(X_train, y_train)\n",
    "    return best_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "49bd199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_paramter = param_tunning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7a2ab973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5, 'learning_rate': 0.04, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 250, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(best_paramter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d325d",
   "metadata": {},
   "source": [
    "## Tuned Model Re-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6d940dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:11:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of XGBoosting classifier on training set: 0.99\n",
      "Accuracy of XGBoosting classifier on test set: 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.97      0.93      0.95      1054\n",
      "    NonFraud       0.97      0.99      0.98      2446\n",
      "\n",
      "    accuracy                           0.97      3500\n",
      "   macro avg       0.97      0.96      0.96      3500\n",
      "weighted avg       0.97      0.97      0.97      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_xgb = xgb.XGBClassifier(colsample_bytree=0.5,\n",
    "                              learning_rate=0.04,\n",
    "                              max_depth=9,\n",
    "                              min_child_weight=5,\n",
    "                              n_estimators=250,\n",
    "                              subsample=1,\n",
    "                              use_label_encoder=False).fit(X_train, y_train)\n",
    "\n",
    "tuned_xgb_pred = tuned_xgb.predict(X_test)\n",
    "\n",
    "print('Accuracy of XGBoosting classifier on training set: {:.2f}'\n",
    "     .format(tuned_xgb.score(X_train, y_train)))\n",
    "print('Accuracy of XGBoosting classifier on test set: {:.2f}'\n",
    "     .format(tuned_xgb.score(X_test, y_test)))\n",
    "print(classification_report(y_test, tuned_xgb_pred, target_names=['Fraud', 'NonFraud']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c97117",
   "metadata": {},
   "source": [
    "# III. Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "61a04b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction using tunned XGB Model\n",
    "FRAUD_NONFRAUD = tuned_xgb.predict(encoded_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2756585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the prediction to current dataset\n",
    "testing_data['FRAUD_NONFRAUD'] = FRAUD_NONFRAUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b0ffaddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export result\n",
    "result = testing_data['FRAUD_NONFRAUD'].copy()\n",
    "result.to_csv(\"Result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24720ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
